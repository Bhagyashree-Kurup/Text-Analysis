# -*- coding: utf-8 -*-
"""Sentiment Predictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eKlYyY8BpARfjSuPMOy0ixcKz1pEciUS
"""

# Importing libraries
import numpy as np
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

# Importing the dataset
dataset = pd.read_csv('./drive/My Drive/a2_RestaurantReviews_FreshDump.tsv', delimiter = '\t', quoting = 3)
dataset.head()

# Importing python's regular expression and natural language toolkit
import re
import nltk

# downloading stopwords file
nltk.download('stopwords')

from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()

all_stopwords = stopwords.words('english')
all_stopwords.remove('not')

# corpus declared for storing data after data cleaning
corpus=[]

for i in range(0, 100):
  # removing all special characters and numbers
  review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])
  # changes reviews into lower case
  review = review.lower()
  # splitting the sentence into words
  review = review.split()
  # removing all stopwords and stemming/lemmatizing the remaining words
  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]
  review = ' '.join(review)
  corpus.append(review)

corpus

# Loading BoW dictionary we saved before
from sklearn.feature_extraction.text import CountVectorizer
import pickle
cvFile='./drive/MyDrive/c1_BoW_Sentiment_Model.pkl'
cv = pickle.load(open(cvFile, "rb"))

X_fresh = cv.transform(corpus).toarray()
X_fresh.shape

# Importing NB Classifier we saved for later use in sentiment prediction
import joblib
classifier = joblib.load('./drive/MyDrive/c2_Classifier_Sentiment_Model')

# Sentiment prediction for fresh reviews
Y_pred = classifier.predict(X_fresh)
print(Y_pred)

dataset['predicted_label'] = Y_pred.tolist()
dataset.head()

dataset.to_csv("./drive/MyDrive/c3_Predicted_Sentiments_Fresh_Dump.tsv", sep='\t', encoding='UTF-8', index=False)